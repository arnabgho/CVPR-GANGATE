\section{Introduction}
Generative methods have made huge strides in the last few years driven by the success of Variational Autoencoders (VAEs)~\cite{kingma2013auto} and Generative Adversarial Networks (GANs)~\cite{goodfellow2014generative}. These methods can generate impressive results but one major challenge is that quality degrades quickly when the diversity of training data (e.g., number of object/scene classes) increases. It is a common practice in this domain to train different models for different datasets \cite{goodfellow2014generative,isola2016image2image,progressiveGAN,zhu2017toward,zhu2017unpaired,...,...,...}, which doesn't scale up with the number of classes. A study performed in \cite{ghosh2017multi} demonstrated that even on a simple setting of Mixture of Gaussians, the state of the art GAN techniques were not able to generate samples from all the components of the mixture. However their proposed method still involved training multiple generators.

%
Veit et al.~\shortcite{veit2016residual} perfromed an innovative set of incision experiments on a trained Residual Network architecture \cite{he2016deep} demonstrated that certain paths in the network played a much more important role for certain classes. They inferred that ResNets behave as an ensemble of several partially disjoint paths for image classification. 
In this paper we analyze the implications of the observations of \cite{veit2016residual} on a Generative Modeling scenario. We start analyzing GANs on a toy dataset of 1D Mixture of Gaussians, similar to the one introduced in \cite{ghosh2017multi}, and discover that after training a ResNet generator and discriminator on the dataset, removal of certain blocks of the generator corresponds to disappearance of certain modes in the generated distribution. We thus introduce a simple {\em soft gating} mechanism where based on the conditioning input (e.g., the class of the object) a hypernetwork predicts which parts of ResNet to use for that particular conditioning. We explore and analyze different types of gating, including a {\em blockwise} and {\em channelwise} gating, a multiplicative and a scale+bias types of soft weighting as well as other related method like AdaIn~\cite{huang2017arbitrary,huang2018multimodal}. We show that a channelwise multiplicative gating performs best for our task. We further show that better results are obtained if gating is applied not not only for a ResNet-based generator but also for a ResNet discriminator.
%

We further introduce a new task of generating multi-class images from rough outline scribbles where gating is particularly useful. Fig.~\ref{fig:teaser} (top left) shows one such example where the same simple scribble yields different outputs of a generator conditioned on ten different classes. In the case of the InfoGAN~\cite{chen2016infogan} setting, which was previously shown to produce limited texture variation~\cite{ghosh2017multi} with na\"\{i}ve concatenation-based conditioning, our method produces diverse generations, as shown in Fig.~\ref{fig:teaser} (top right). In addition, we also introduce the {\em multi-task image-to-image translation}. In its original setting \cite{isola2016image2image}, different trained models had to be introduced for the different translation tasks. Our gating mechanism enables good performance on each task by activating appropriate task-specific blocks and channels (Fig.~\ref{fig:teaser} bottom).

%whereby the rough scribbles divulge almost no information about the class.



%%The technique presented a scenario in which we could generate multiple modes for a single dataset but it could further be used for generating multiple modes from a dataset consisting of multiple classes and the hypernetwork could choose the blocks needed for a particular class. 




%%Furthermore we perform a systematic analysis of all meaningful gating mechanisms and other forms of conditioning in the setting of a image conditioned generative model. This paper also finds that gating also enables the discriminator to provide better class conditioned gradients back to the generator for high quality generations.


% Generative methods have made huge strides in the last few years driven by the success of Variational Autoencoders (VAEs)~\cite{kingma2013auto} and Generative Adversarial Networks (GANs)~\cite{goodfellow2014generative}. 
% While these methods can generate impressive results, one major challenge is that quality degrades quickly when the diversity of training data (e.g., number of object/scene classes) increases, especially when the manifold of the multi-class distribution of images drawn from the ground truth distribution is not continuous. \ow{um... I don't really get this previous sentence}

% We propose a solution to generate multi-class images using a form of class conditioning that outperforms prior class conditioned GANs while requiring significantly fewer parameters than using a single GAN per-class. 
% To do this, we take advantage of the fact that different classes will share similar visual features, and propose an architecture wherein a fully-residual GAN generator and discriminator, is combined with a second ``gating'' network, which determines how the network is conditioned on the input class.

% We compare various forms of gating, such as concatenating one-hot class information, auxillary classification, \todo{...}.

% We evaluate our gating approach on a number of applications \todo{...}
% \ow{discuss evaluation and findings}
%
In summary, our contributions are:
\begin{itemize}
\item An in-depth analysis of the role of gating networks in generative modeling.
\item A novel architecture using a gating hypernetwork that can generate diverse multi-class results for both class conditioned and InfoGAN-style applications. 
%\item Incision experiments on a trained Residual Generator based GAN on the 1D Mixture of Gaussians to show certain blocks correspond to certain modes in the generated distribution.
%\item Introduction of the Gated Residual Blocks and the Hypernetwork to predict the corresponding alphas on the Generator and Discriminator.
\item Introduction of a new image-to-image translation task of generating realistic images from very rough outline scribbles.
\end{itemize}